# Policy & Standards Mapping (UN Charter → NIST AI RMF → EU AI Act)

**File path to commit in your repo:** `/docs/policy-mapping.md`  
**Purpose:** One-table mapping that ties UN/UNESCO principles to NIST AI RMF outcomes and EU AI Act obligations. Each row ends with a **decision code** for your Safety Agent/UI.

---

## Decision Code Legend (default behavior)
- **BLOCK** – deny the request/output; log with reason code; notify reviewer.
- **REVIEW** – route to human reviewer; hold action/output until approved; capture evidence.
- **SANITIZE** – automatically redact/transform (e.g., PII masking, link stripping), then **REVIEW** (unless otherwise stated).
- **DE-IDENTIFY+REVIEW** – remove direct/indirect identifiers, then route to human.
- **ALLOW** – proceed; log decision & rationale.

> NIST wording is used for **Functions→Outcomes** to keep this table reviewable against the NIST AI RMF Playbook.

---

## Unified Mapping Table

| Policy Source | Clause / Principle | NIST RMF Function → Outcome (examples) | EU AI Act duty (tier) | Example Hazard | Decision Code (default) |
|---|---|---|---|---|---|
| **UN Charter** | **Art. 1(3)** – promote and encourage respect for **human rights** and fundamental freedoms | **GOVERN** – policies, processes, roles embed human rights commitments; **MANAGE** – risk treatments enacted and monitored | **GPAI transparency** (model & output disclosures); **High‑risk controls** where applicable (risk mgmt, data governance, human oversight, logging, robustness/cybersecurity) | Hate/incitement targeting protected groups | **BLOCK** |
| **UN Charter** | **Art. 2(3)–(4)** – peaceful settlement; refrain from threat or use of force | **GOVERN** – organizational policies prohibit violence advocacy; **MANAGE** – incident response for unsafe content | **Prohibited practices / illegal content alignment**; **GPAI transparency** | “How to make a bomb”/violence facilitation | **BLOCK** |
| **UNESCO AI Ethics (2021)** | **Human dignity & human rights** | **MAP** – affected populations & rights impacts documented; **MEASURE** – metrics/checks for rights harms | **High‑risk**: risk mgmt + technical docs + human oversight + accuracy/robustness; **GPAI transparency** | Exposure of sensitive personal data (PII/health/child data) | **SANITIZE** |
| **UNESCO AI Ethics (2021)** | **Fairness & non‑discrimination** | **MAP** – context & intended purpose incl. bias contexts; **MEASURE** – bias tests & performance disaggregations | **High‑risk** (e.g., employment, credit, education): data governance, risk mgmt, human oversight, logging, accuracy/robustness | Discriminatory scoring in hiring or credit | **REVIEW** (block deployment until bias mitigations) |
| **UNESCO AI Ethics (2021)** | **Human oversight & accountability** | **MANAGE** – human‑in‑the‑loop/approval for high‑impact actions; **GOVERN** – roles & escalation | **High‑risk**: effective human oversight; **Post‑market monitoring** | Fully automated adverse decision with no effective oversight | **REVIEW** |
| **UNESCO AI Ethics (2021)** | **Privacy & data governance** | **GOVERN** – data policies and role‑based access; **MEASURE** – privacy leakage tests | **High‑risk**: data governance, logging; **GPAI**: training data transparency | Output contains names + contact details scraped from untrusted sources | **DE‑IDENTIFY+REVIEW** |
| **UNESCO AI Ethics (2021)** | **Transparency & explainability** | **MAP** – document intended use, limitations, known unknowns; **MEASURE** – evaluate explainability/faithfulness | **User transparency** (instructions, disclosures); **High‑risk**: technical documentation & instructions for use | Opaque recommendation affecting benefits eligibility | **REVIEW** |
| **UNESCO AI Ethics (2021)** | **Environment & ecosystem** | **GOVERN** – sustainability objectives; **MEASURE** – track energy/carbon & robustness tradeoffs | **Provider duties** to mitigate systemic risk (for powerful GPAI); risk mgmt for high‑risk | Excessive compute without mitigation; unsafe degradation under stress | **REVIEW** |
| **UN Core Values** | **Integrity** (truthfulness; avoid deception) | **MEASURE** – groundedness/factuality checks; **MANAGE** – corrective actions for model errors | **GPAI transparency**; **High‑risk**: record‑keeping & logging obligations | Fabricated citations / misinformation | **REVIEW** |
| **OWASP LLM Top‑10 (2025)** | **Prompt Injection** | **MEASURE** – adversarial testing; **MANAGE** – enforce least‑privilege & human approval for risky tools | **GPAI**: model evals/adversarial testing; **High‑risk**: robustness & cybersecurity | Untrusted page injects instructions to exfiltrate data | **BLOCK** (on tool call) |
| **OWASP LLM Top‑10 (2025)** | **Improper Output Handling** | **MANAGE** – output validation & sanitization gates; **GOVERN** – secure coding policies | **Provider/User duties** to ensure safe integration; **High‑risk**: logging, cybersecurity | LLM returns HTML/JS executed downstream (XSS/RCE) | **SANITIZE** |
| **UN Charter / UNESCO** | **Non‑discrimination; equality** | **MAP** – stakeholder engagement incl. vulnerable groups; **MEASURE** – disparate impact | **High‑risk**: employment/credit/education obligations; **GPAI** transparency | Targeted harassment/dehumanization of protected groups | **BLOCK** |
| **UNESCO / Child protection focus** | **Protect children’s rights & well‑being** | **GOVERN** – age‑appropriate policies; **MANAGE** – stricter routing & review | **High‑risk** if impacting children; **GPAI**: safety disclosures | Requests for minors’ PII; content sexualizing minors | **BLOCK** |
| **UN Charter / Accountability** | **Rule of law; justice** | **GOVERN** – logging, traceability, auditability; **MANAGE** – incident mgmt & corrective actions | **High‑risk**: logging/traceability & post‑market monitoring; incident reporting | Missing logs/trace IDs for adverse decisions | **REVIEW** (hold until instrumented) |
| **UN Charter / UNESCO** | **Respect for cultural diversity** | **MAP** – context & localization documented; **MEASURE** – testing across languages/cultures | **High‑risk**: instructions for use & risk mgmt cover localization | Harmful stereotypes in localized outputs | **REVIEW** |

---

## Notes & Sources (for auditors)

- **UN Charter, Chapter I (Articles 1–2)** – Purposes (incl. *“promoting and encouraging respect for human rights”*) and Principles (peaceful settlement, sovereign equality). See UN official text and Chapter I page.  
- **UNESCO Recommendation on the Ethics of AI (2021)** – values & principles: human rights & dignity, fairness/non‑discrimination, human oversight, transparency, privacy/data governance, environment/ecosystems.  
- **NIST AI Risk Management Framework (AI RMF 1.0)** and **NIST AI RMF Playbook** – Functions **GOVERN, MAP, MEASURE, MANAGE** and their Outcomes; Playbook lists *suggested actions* aligned to these Outcomes.  
- **EU AI Act** – entered into force **1 Aug 2024**; staged applicability: **prohibitions & AI literacy obligations from 2 Feb 2025**; **GPAI & governance rules from 2 Aug 2025**; **general application from 2 Aug 2026**; some **embedded high‑risk systems extended to 2 Aug 2027**. Use these dates to tag compliance evidence in your acceptance matrix.  
- **OWASP Top‑10 for LLM Applications (2025)** – canonical hazards and mitigations for **Prompt Injection** and **Improper Output Handling** used here as example hazards.

---

### How to use this table in your UI/Agent
1. **Tag every decision** with: (a) UN/UNESCO principle(s), (b) **NIST Function→Outcome**, (c) **EU AI Act duty/tier**, and (d) the **Decision Code** above.  
2. **Evidence export** should include: user input/output, hazard classifier scores, rule fired, decision code, reviewer action (if any), and source tags (UN/NIST/EU).  
3. **Zero‑tolerance categories** (e.g., explicit incitement, sexual content involving minors, doxxing minors) remain **BLOCK**.  
4. **Adversarial & output‑handling checks** must run before tool calls and before rendering potentially executable content.


### References (official sources)
- UN Charter – Chapter I (Purposes & Principles): https://www.un.org/en/about-us/un-charter/chapter-1
- UN Charter – Full text (PDF): https://treaties.un.org/doc/publication/ctc/uncharter.pdf
- UNESCO Recommendation on the Ethics of AI (overview): https://www.unesco.org/en/artificial-intelligence/recommendation-ethics
- NIST AI Risk Management Framework (AI RMF 1.0, PDF): https://nvlpubs.nist.gov/nistpubs/ai/nist.ai.100-1.pdf
- NIST AI RMF Playbook (Outcomes & suggested actions): https://www.nist.gov/itl/ai-risk-management-framework/nist-ai-rmf-playbook
- EU AI Act enters into force (European Commission): https://commission.europa.eu/news-and-media/news/ai-act-enters-force-2024-08-01_en
- EU AI Act – Application timeline (EC Digital Strategy): https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai
- EU AI Act – Implementation timeline (European Parliament brief): https://www.europarl.europa.eu/RegData/etudes/ATAG/2025/772906/EPRS_ATA%282025%29772906_EN.pdf
- OWASP Top‑10 for LLM Applications 2025 (PDF): https://owasp.org/www-project-top-10-for-large-language-model-applications/assets/PDF/OWASP-Top-10-for-LLMs-v2025.pdf
- OWASP – Prompt Injection (overview): https://genai.owasp.org/llmrisk/llm01-prompt-injection/
- OWASP – Improper Output Handling (overview): https://genai.owasp.org/llmrisk/llm05-supply-chain-vulnerabilities/
